#!/usr/bin/env python3
"""
Company Discovery Tool â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ñ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸ÑĞ¼Ğ¸

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Claude API Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° tech-ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ñ†ĞµĞ»ĞµĞ²Ñ‹Ñ… Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸ÑÑ… (NC + Remote US).
ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ATS, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ»ĞµĞ¹, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ² staging area.

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
    python tools/company_discovery.py search           # AI-Ğ¿Ğ¾Ğ¸ÑĞº + seed list
    python tools/company_discovery.py search --ai-only # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ AI-Ğ¿Ğ¾Ğ¸ÑĞº
    python tools/company_discovery.py search --seed-only  # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ seed list
    python tools/company_discovery.py list             # Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²
    python tools/company_discovery.py validate         # Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ATS + URL
    python tools/company_discovery.py preview          # preview Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ»ĞµĞ¹
"""

import json
import os
import re
import sys
import requests
from pathlib import Path
from datetime import datetime
from urllib.parse import urlparse

from dotenv import load_dotenv

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

COMPANIES_FILE = PROJECT_ROOT / "data" / "companies.json"
STAGING_FILE = PROJECT_ROOT / "data" / "discovered_companies.json"

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ .env
load_dotenv(PROJECT_ROOT / ".env", override=True)

# ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ ATS (Ğ¸Ğ· main.py ATS_PARSERS)
SUPPORTED_ATS = ["greenhouse", "lever", "smartrecruiters", "ashby", "workday", "atlassian", "phenom"]

# Ğ¦ĞµĞ»ĞµĞ²Ñ‹Ğµ Ñ€Ğ¾Ğ»Ğ¸ (Ğ¸Ğ· config/roles.json â€” primary category)
TARGET_ROLES = [
    "Product Manager", "Technical Program Manager", "Program Manager",
    "Product Owner", "Project Manager", "Delivery Manager",
    "Scrum Master", "Release Manager", "Project Lead",
]

# Ğ¦ĞµĞ»ĞµĞ²Ñ‹Ğµ Ğ»Ğ¾ĞºĞ°Ñ†Ğ¸Ğ¸
TARGET_STATE = "NC"
TARGET_CITIES = ["Raleigh", "Durham", "Charlotte", "Cary", "Morrisville", "Research Triangle"]


def load_companies() -> list:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· companies.json"""
    with open(COMPANIES_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def load_staging() -> list:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ staging area"""
    if not STAGING_FILE.exists():
        return []
    with open(STAGING_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def save_staging(candidates: list):
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ staging area"""
    with open(STAGING_FILE, "w", encoding="utf-8") as f:
        json.dump(candidates, f, indent=2, ensure_ascii=False)
    print(f"  ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ {len(candidates)} ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ² {STAGING_FILE.name}")


def get_existing_ids() -> set:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ id Ğ¸ Ğ¸Ğ¼Ñ‘Ğ½ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹"""
    companies = load_companies()
    ids = set()
    for c in companies:
        ids.add(c.get("id", "").lower())
        ids.add(c.get("name", "").lower())
    return ids


def get_staging_ids() -> set:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ id ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ² staging"""
    return {c.get("id", "").lower() for c in load_staging()}


def call_claude_api(prompt: str, max_tokens: int = 4000) -> str | None:
    """Ğ’Ñ‹Ğ·Ğ¾Ğ² Claude API"""
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âŒ ANTHROPIC_API_KEY not set in .env")
        return None

    try:
        import anthropic
        client = anthropic.Anthropic(api_key=api_key)
        message = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}]
        )
        return message.content[0].text
    except ImportError:
        print("âŒ anthropic package not installed. Run: pip install anthropic")
        return None
    except Exception as e:
        print(f"âŒ Claude API error: {e}")
        return None


# ===== ATS Detection (Ğ¸Ğ· data_cleanup.py) =====

def detect_ats_from_board_url(board_url: str) -> dict | None:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ATS Ğ¿Ğ¾ URL Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñƒ board_url"""
    if not board_url:
        return None

    parsed = urlparse(board_url)
    host = parsed.netloc.lower()
    path = parsed.path

    if "greenhouse.io" in host:
        slug = path.strip("/").split("/")[0] if path.strip("/") else ""
        if slug:
            return {"ats": "greenhouse", "board_url": f"https://boards.greenhouse.io/{slug}"}

    if "lever.co" in host:
        slug = path.strip("/").split("/")[0] if path.strip("/") else ""
        if slug:
            return {"ats": "lever", "board_url": f"https://jobs.lever.co/{slug}"}

    if "smartrecruiters.com" in host:
        slug = path.strip("/").split("/")[0] if path.strip("/") else ""
        if slug:
            return {"ats": "smartrecruiters", "board_url": f"https://jobs.smartrecruiters.com/{slug}"}

    if "ashbyhq.com" in host:
        slug = path.strip("/").split("/")[0] if path.strip("/") else ""
        if slug:
            return {"ats": "ashby", "board_url": f"https://jobs.ashbyhq.com/{slug}"}

    if "myworkdayjobs.com" in host:
        parts = host.split(".")
        company = parts[0] if parts else ""
        wd_match = re.search(r"\.(wd\d+)\.", host)
        wd_num = wd_match.group(1) if wd_match else "wd1"
        site_match = re.search(r"myworkdayjobs\.com/(?:[a-z][a-z]-[A-Z][A-Z]/)?([^/]+)", board_url)
        site = site_match.group(1) if site_match else company
        return {"ats": "workday", "board_url": f"https://{company}.{wd_num}.myworkdayjobs.com/{site}"}

    if "icims.com" in host:
        subdomain = host.split(".")[0]
        return {"ats": "icims", "board_url": f"https://{subdomain}.icims.com/jobs"}

    return None


def try_detect_ats_via_http(board_url: str) -> dict | None:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ATS Ñ‡ĞµÑ€ĞµĞ· HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ´Ğ¸Ñ€ĞµĞºÑ‚Ñ‹ Ğ¸ HTML"""
    try:
        r = requests.get(board_url, timeout=15, allow_redirects=True, headers={
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        })
        final_url = r.url.lower()

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€ĞµĞ´Ğ¸Ñ€ĞµĞºÑ‚
        redirect_result = detect_ats_from_board_url(final_url)
        if redirect_result:
            return redirect_result

        # Ğ˜Ñ‰ĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ² HTML
        html = r.text[:10000].lower()

        ats_patterns = {
            "greenhouse": [r"boards\.greenhouse\.io/([a-z0-9_-]+)"],
            "lever": [r"jobs\.lever\.co/([a-z0-9_-]+)"],
            "ashby": [r"jobs\.ashbyhq\.com/([a-z0-9_-]+)"],
            "smartrecruiters": [r"jobs\.smartrecruiters\.com/([a-zA-Z0-9_-]+)"],
        }

        for ats, patterns in ats_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, html)
                if match:
                    slug = match.group(1)
                    url_templates = {
                        "greenhouse": f"https://boards.greenhouse.io/{slug}",
                        "lever": f"https://jobs.lever.co/{slug}",
                        "ashby": f"https://jobs.ashbyhq.com/{slug}",
                        "smartrecruiters": f"https://jobs.smartrecruiters.com/{slug}",
                    }
                    return {"ats": ats, "board_url": url_templates[ats]}

    except Exception as e:
        print(f"    âš ï¸ HTTP Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ»Ñ {board_url}: {e}")

    return None


def detect_and_validate(careers_url: str) -> dict:
    """
    ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ATS Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ URL.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚: {ats, board_url, ats_verified, supported}
    """
    result = {"ats": None, "board_url": careers_url, "ats_verified": False, "supported": False}

    # Ğ¨Ğ°Ğ³ 1: URL Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½
    detected = detect_ats_from_board_url(careers_url)
    if detected:
        result.update(detected)
        result["ats_verified"] = True
        result["supported"] = detected["ats"] in SUPPORTED_ATS
        return result

    # Ğ¨Ğ°Ğ³ 2: HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
    detected = try_detect_ats_via_http(careers_url)
    if detected:
        result.update(detected)
        result["ats_verified"] = True
        result["supported"] = detected["ats"] in SUPPORTED_ATS
        return result

    result["ats"] = "unknown"
    return result


# ===== AI Discovery =====

def build_discovery_prompt(existing_names: set) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ AI-Ğ¿Ğ¾Ğ¸ÑĞºĞ° ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹"""
    existing_list = ", ".join(sorted(list(existing_names))[:50])

    prompt = f"""Ğ¯ Ğ¸Ñ‰Ñƒ tech-ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Product Manager, TPM, Program Manager, Project Manager.

Ğ¤Ğ¾ĞºÑƒÑ: Ğ¡ĞµĞ²ĞµÑ€Ğ½Ğ°Ñ ĞšĞ°Ñ€Ğ¾Ğ»Ğ¸Ğ½Ğ° (NC) â€” Raleigh, Durham, Charlotte, Research Triangle Park.
Ğ¢Ğ°ĞºĞ¶Ğµ: ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ US tech-ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ñ remote-Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑĞ¼Ğ¸.

Ğ£ Ğ¼ĞµĞ½Ñ Ğ£Ğ–Ğ• ĞµÑÑ‚ÑŒ ÑÑ‚Ğ¸ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ (ĞĞ• Ğ²ĞºĞ»ÑÑ‡Ğ°Ğ¹ Ğ¸Ñ…):
{existing_list}

ĞœĞ½Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹ ĞĞĞ’Ğ«Ğ• ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸, Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ…:
1. Ğ•ÑÑ‚ÑŒ ĞºĞ°Ñ€ÑŒĞµÑ€Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° / job board (Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)
2. Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ Ğ½Ğ°Ğ½Ğ¸Ğ¼Ğ°ÑÑ‚ PM/TPM/Program Manager
3. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸Ğ· ATS: Greenhouse, Lever, SmartRecruiters, Ashby, Workday (Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)

Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ ÑƒĞºĞ°Ğ¶Ğ¸:
- name: Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ
- careers_url: URL ĞºĞ°Ñ€ÑŒĞµÑ€Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ (Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ™, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼Ñ‹Ğ¹ URL)
- hq_state: ÑˆÑ‚Ğ°Ñ‚ ÑˆÑ‚Ğ°Ğ±-ĞºĞ²Ğ°Ñ€Ñ‚Ğ¸Ñ€Ñ‹ (2 Ğ±ÑƒĞºĞ²Ñ‹) Ğ¸Ğ»Ğ¸ null
- industry: IT, Fintech, Healthcare, Consulting, Gaming, Retail, Banking, Security, AI/ML, Data, DevTools, Enterprise SaaS, Cloud, E-commerce, Social, EdTech, Hardware, Biotech, Telecommunications, Manufacturing, Other
- tags: 1-3 Ñ‚ĞµĞ³Ğ° Ğ¸Ğ· [security, devtools, cloud, ai, data, fintech, saas, hr, enterprise, gaming, healthtech, biotech, consulting, software, edtech, payments, analytics, ecommerce, hardware, retail]
- reasoning: Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ğ° ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ (1 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ)

Ğ’ĞĞ–ĞĞ:
- ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ #1: NC ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ñ Ğ¾Ñ„Ğ¸ÑĞ°Ğ¼Ğ¸ Ğ² Research Triangle / Charlotte
- ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ #2: ĞšÑ€ÑƒĞ¿Ğ½Ñ‹Ğµ US tech Ñ remote-friendly PM Ñ€Ğ¾Ğ»ÑĞ¼Ğ¸
- Ğ”Ğ°Ğ²Ğ°Ğ¹ 15-25 ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹
- URL Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«ĞœĞ˜ (Ğ½Ğµ Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹)
- ĞĞµ Ğ²ĞºĞ»ÑÑ‡Ğ°Ğ¹ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· Ğ¼Ğ¾ĞµĞ³Ğ¾ ÑĞ¿Ğ¸ÑĞºĞ°

ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ¡Ğ¢Ğ ĞĞ“Ğ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON-Ğ¼Ğ°ÑÑĞ¸Ğ²Ğ° Ğ±ĞµĞ· markdown-Ğ±Ğ»Ğ¾ĞºĞ¾Ğ²:
[
  {{"name": "...", "careers_url": "...", "hq_state": "NC", "industry": "IT", "tags": ["software"], "reasoning": "..."}},
  ...
]
"""
    return prompt


def parse_discovery_response(response: str) -> list:
    """ĞŸĞ°Ñ€ÑĞ¸Ğ¼ JSON Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Claude"""
    text = response.strip()
    if text.startswith("```"):
        lines = text.split("\n")
        text = "\n".join(lines[1:-1])

    try:
        result = json.loads(text)
        if isinstance(result, list):
            return result
    except json.JSONDecodeError as e:
        print(f"  âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° JSON: {e}")
        print(f"  ĞÑ‚Ğ²ĞµÑ‚: {text[:200]}...")
    return []


def discover_via_ai(existing_ids: set, existing_names: set) -> list:
    """ĞŸĞ¾Ğ¸ÑĞº ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Claude API"""
    print("\nğŸ¤– AI-Ğ¿Ğ¾Ğ¸ÑĞº ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹...")

    prompt = build_discovery_prompt(existing_names)
    response = call_claude_api(prompt, max_tokens=6000)

    if not response:
        print("  âŒ ĞĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ñ‚ Claude API")
        return []

    suggestions = parse_discovery_response(response)
    print(f"  ğŸ“‹ Claude Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ğ» {len(suggestions)} ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹")

    candidates = []
    for s in suggestions:
        name = s.get("name", "")
        careers_url = s.get("careers_url", "")

        if not name or not careers_url:
            continue

        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ id
        cid = re.sub(r"[^a-z0-9]", "-", name.lower()).strip("-")
        cid = re.sub(r"-+", "-", cid)

        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞµÑĞ»Ğ¸ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        if cid in existing_ids or name.lower() in existing_ids:
            print(f"    â­ï¸ {name} â€” ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚")
            continue

        candidates.append({
            "id": cid,
            "name": name,
            "careers_url": careers_url,
            "hq_state": s.get("hq_state"),
            "industry": s.get("industry", ""),
            "tags": s.get("tags", []),
            "discovery_source": "ai_suggestion",
            "reasoning": s.get("reasoning", ""),
            "discovered_at": datetime.now().isoformat(),
            "ats": None,
            "board_url": None,
            "ats_verified": False,
            "supported": False,
            "relevant_roles_count": None,
            "status": "pending_validation",
        })

    return candidates


# ===== Seed List (ĞºÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº NC tech-ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹) =====

# ĞšĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· NC / Research Triangle ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ Ğ½Ğ°Ğ½Ğ¸Ğ¼Ğ°ÑÑ‚ PM
NC_SEED_LIST = [
    {"name": "Epic Games", "careers_url": "https://boards.greenhouse.io/epicgames", "hq_state": "NC", "industry": "Gaming", "tags": ["gaming", "software"]},
    {"name": "Cisco (RTP)", "careers_url": "https://jobs.cisco.com", "hq_state": "CA", "industry": "IT", "tags": ["networking", "enterprise"]},
    {"name": "IBM (RTP)", "careers_url": "https://www.ibm.com/careers", "hq_state": "NY", "industry": "IT", "tags": ["enterprise", "cloud", "ai"]},
    {"name": "NetApp", "careers_url": "https://jobs.smartrecruiters.com/NetApp", "hq_state": "CA", "industry": "IT", "tags": ["storage", "cloud"]},
    {"name": "Fidelity Investments (Durham)", "careers_url": "https://jobs.fidelity.com", "hq_state": "MA", "industry": "Fintech", "tags": ["fintech", "investment"]},
    {"name": "MetLife (Cary)", "careers_url": "https://jobs.metlife.com", "hq_state": "NY", "industry": "Fintech", "tags": ["fintech", "enterprise"]},
    {"name": "Lenovo (Morrisville)", "careers_url": "https://jobs.lenovo.com", "hq_state": "NC", "industry": "Hardware", "tags": ["hardware", "enterprise"]},
    {"name": "Credit Suisse (RTP)", "careers_url": "https://www.credit-suisse.com/careers", "hq_state": None, "industry": "Banking", "tags": ["banking", "fintech"]},
    {"name": "Allscripts (Raleigh)", "careers_url": "https://www.veracitynetworks.com/careers", "hq_state": "NC", "industry": "Healthcare", "tags": ["healthtech"]},
    {"name": "Dude Solutions", "careers_url": "https://boards.greenhouse.io/dudesolutions", "hq_state": "NC", "industry": "Enterprise SaaS", "tags": ["saas", "enterprise"]},
    {"name": "Spreedly", "careers_url": "https://boards.greenhouse.io/spreedly", "hq_state": "NC", "industry": "Fintech", "tags": ["fintech", "payments"]},
    {"name": "iCIMS", "careers_url": "https://careers.icims.com", "hq_state": "NJ", "industry": "Enterprise SaaS", "tags": ["saas", "hr"]},
    {"name": "Avalara", "careers_url": "https://jobs.lever.co/avalara", "hq_state": "WA", "industry": "Fintech", "tags": ["fintech", "saas", "compliance"]},
    {"name": "Cree (Durham)", "careers_url": "https://www.wolfspeed.com/company/careers", "hq_state": "NC", "industry": "Hardware", "tags": ["hardware"]},
    {"name": "Prometheus Group", "careers_url": "https://boards.greenhouse.io/prometheusgroup", "hq_state": "NC", "industry": "Enterprise SaaS", "tags": ["saas", "enterprise"]},
    {"name": "Relay (Raleigh)", "careers_url": "https://boards.greenhouse.io/relaypro", "hq_state": "NC", "industry": "IT", "tags": ["hardware", "communications"]},
    {"name": "Windsor Group (Raleigh)", "careers_url": "https://www.thewindsorgroup.com/careers", "hq_state": "NC", "industry": "Consulting", "tags": ["consulting"]},
    {"name": "Arch Capital Services", "careers_url": "https://archgroup.wd5.myworkdayjobs.com/Arch", "hq_state": "NC", "industry": "Fintech", "tags": ["fintech"]},
    {"name": "nCino (Wilmington NC)", "careers_url": "https://boards.greenhouse.io/ncino", "hq_state": "NC", "industry": "Fintech", "tags": ["fintech", "banking", "saas"]},
    {"name": "Lowe's (Mooresville NC)", "careers_url": "https://talent.lowes.com", "hq_state": "NC", "industry": "Retail", "tags": ["retail", "ecommerce"]},
]


def discover_from_seed_list(existing_ids: set) -> list:
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ Ğ¸Ğ· ĞºÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ seed list"""
    print("\nğŸ“‹ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ seed list NC-ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¹...")

    staging_ids = get_staging_ids()
    candidates = []

    for seed in NC_SEED_LIST:
        name = seed["name"]
        careers_url = seed["careers_url"]

        # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ id
        # Ğ”Ğ»Ñ seed Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‡Ğ¸ÑÑ‚Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ±ĞµĞ· ÑĞºĞ¾Ğ±Ğ¾Ğº
        clean_name = re.sub(r"\s*\(.*?\)\s*", " ", name).strip()
        cid = re.sub(r"[^a-z0-9]", "-", clean_name.lower()).strip("-")
        cid = re.sub(r"-+", "-", cid)

        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞµÑĞ»Ğ¸ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        if cid in existing_ids or name.lower() in existing_ids:
            print(f"    â­ï¸ {name} â€” ÑƒĞ¶Ğµ Ğ² companies.json")
            continue
        if cid in staging_ids:
            print(f"    â­ï¸ {name} â€” ÑƒĞ¶Ğµ Ğ² staging")
            continue

        candidates.append({
            "id": cid,
            "name": name,
            "careers_url": careers_url,
            "hq_state": seed.get("hq_state"),
            "industry": seed.get("industry", ""),
            "tags": seed.get("tags", []),
            "discovery_source": "seed_list_nc",
            "reasoning": f"NC tech company seed list",
            "discovered_at": datetime.now().isoformat(),
            "ats": None,
            "board_url": None,
            "ats_verified": False,
            "supported": False,
            "relevant_roles_count": None,
            "status": "pending_validation",
        })
        print(f"    â• {name} ({careers_url})")

    return candidates


# ===== Validation =====

def validate_candidates(candidates: list) -> int:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ATS Ğ´Ğ»Ñ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² ÑĞ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ¾Ğ¼ pending_validation"""
    changes = 0
    pending = [c for c in candidates if c.get("status") == "pending_validation"]

    print(f"\nğŸ” Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ {len(pending)} ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²...")

    for c in pending:
        cid = c["id"]
        careers_url = c.get("careers_url", "")
        print(f"  [{cid}] {careers_url}")

        result = detect_and_validate(careers_url)

        c["ats"] = result["ats"]
        c["board_url"] = result["board_url"]
        c["ats_verified"] = result["ats_verified"]
        c["supported"] = result["supported"]

        if result["supported"]:
            c["status"] = "validated"
            print(f"    âœ… {result['ats']} â†’ {result['board_url']}")
        elif result["ats"] and result["ats"] != "unknown":
            c["status"] = "unsupported_ats"
            print(f"    ğŸŸ¡ {result['ats']} (Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ)")
        else:
            c["status"] = "no_ats_detected"
            print(f"    âŒ ATS Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½")

        changes += 1

    return changes


# ===== Preview Roles =====

def preview_relevant_roles(candidates: list) -> int:
    """
    Ğ”Ğ»Ñ validated ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² â€” Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ¸ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ»ĞµĞ¹.
    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ğ°Ñ€ÑĞµÑ€Ñ‹ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ (Ğ±ĞµĞ· refresh_company_sync).
    """
    validated = [c for c in candidates if c.get("status") == "validated" and c.get("supported")]

    if not validated:
        print("\nğŸ“Š ĞĞµÑ‚ validated ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ preview")
        return 0

    print(f"\nğŸ“Š Preview Ñ€Ğ¾Ğ»ĞµĞ¹ Ğ´Ğ»Ñ {len(validated)} ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²...")

    # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ°Ñ€ÑĞµÑ€Ñ‹
    try:
        from parsers.greenhouse import fetch_greenhouse
        from parsers.lever import fetch_lever
        from parsers.smartrecruiters import fetch_smartrecruiters
        from parsers.ashby import fetch_ashby_jobs
        from parsers.workday import fetch_workday
    except ImportError as e:
        print(f"  âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ¿Ğ°Ñ€ÑĞµÑ€Ğ¾Ğ²: {e}")
        return 0

    ats_fetchers = {
        "greenhouse": lambda url: fetch_greenhouse("", url),
        "lever": lambda url: fetch_lever("", url),
        "smartrecruiters": lambda url: fetch_smartrecruiters("", url),
        "ashby": fetch_ashby_jobs,
        "workday": lambda url: fetch_workday("", url),
    }

    # ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ° Ğ´Ğ»Ñ Ñ€Ğ¾Ğ»ĞµĞ¹
    role_keywords = [
        "product manager", "program manager", "project manager",
        "tpm", "technical program", "product owner",
        "delivery manager", "scrum master", "release manager",
        "project lead",
    ]

    changes = 0
    for c in validated:
        cid = c["id"]
        ats = c["ats"]
        board_url = c["board_url"]

        fetcher = ats_fetchers.get(ats)
        if not fetcher:
            continue

        print(f"  [{cid}] ĞŸĞ°Ñ€ÑĞ¸Ğ¼ {ats}: {board_url}...")

        try:
            jobs = fetcher(board_url)
            total_jobs = len(jobs) if jobs else 0

            # Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğµ Ñ€Ğ¾Ğ»Ğ¸
            relevant = 0
            relevant_titles = []
            for job in (jobs or []):
                title = job.get("title", "").lower()
                if any(kw in title for kw in role_keywords):
                    relevant += 1
                    relevant_titles.append(job.get("title", ""))

            c["relevant_roles_count"] = relevant
            c["total_jobs_count"] = total_jobs
            c["relevant_titles_sample"] = relevant_titles[:5]

            if relevant > 0:
                c["status"] = "ready_to_approve"
                print(f"    âœ… {total_jobs} Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹, {relevant} Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ…")
                for t in relevant_titles[:3]:
                    print(f"       â€¢ {t}")
            else:
                c["status"] = "no_relevant_roles"
                print(f"    âš ï¸ {total_jobs} Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹, 0 Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ»ĞµĞ¹")

            changes += 1
        except Exception as e:
            print(f"    âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°: {e}")
            c["status"] = "parse_error"
            c["error"] = str(e)
            changes += 1

    return changes


# ===== List Candidates =====

def list_candidates():
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ¸Ğ· staging"""
    candidates = load_staging()

    if not candidates:
        print("\nğŸ“‹ Staging Ğ¿ÑƒÑÑ‚. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ: python tools/company_discovery.py search")
        return

    # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ÑÑ‚Ğ°Ñ‚ÑƒÑÑƒ
    by_status = {}
    for c in candidates:
        status = c.get("status", "unknown")
        by_status.setdefault(status, []).append(c)

    status_emojis = {
        "ready_to_approve": "âœ…",
        "validated": "ğŸ”",
        "pending_validation": "â³",
        "unsupported_ats": "ğŸŸ¡",
        "no_ats_detected": "âŒ",
        "no_relevant_roles": "âš ï¸",
        "parse_error": "ğŸ’¥",
        "approved": "ğŸ‰",
        "rejected": "ğŸš«",
    }

    print(f"\nğŸ“‹ Discovered Companies ({len(candidates)} total)")
    print("=" * 60)

    for status, items in sorted(by_status.items()):
        emoji = status_emojis.get(status, "â“")
        print(f"\n{emoji} {status} ({len(items)}):")
        for c in items:
            ats = c.get("ats", "?")
            roles = c.get("relevant_roles_count")
            roles_str = f", {roles} PM roles" if roles is not None else ""
            source = c.get("discovery_source", "?")
            print(f"  [{c['id']}] {c.get('name')} â€” ats={ats}{roles_str} (from: {source})")


# ===== Main =====

def main():
    if len(sys.argv) < 2:
        print("""
Company Discovery Tool
======================

Usage:
  python tools/company_discovery.py search            # AI + seed list Ğ¿Ğ¾Ğ¸ÑĞº
  python tools/company_discovery.py search --ai-only  # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ AI
  python tools/company_discovery.py search --seed-only # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ seed list
  python tools/company_discovery.py validate           # Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ATS
  python tools/company_discovery.py preview            # Ğ¿Ğ°Ñ€ÑĞ¸Ğ¼ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸
  python tools/company_discovery.py list               # ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²

Pipeline: search â†’ validate â†’ preview â†’ approve (Ñ‡ĞµÑ€ĞµĞ· API)
        """)
        return

    command = sys.argv[1]

    if command == "search":
        ai_only = "--ai-only" in sys.argv
        seed_only = "--seed-only" in sys.argv

        print("\nğŸ” Company Discovery")
        print("=" * 50)

        existing_ids = get_existing_ids()
        existing_names = {c.get("name", "") for c in load_companies()}
        candidates = load_staging()
        initial_count = len(candidates)

        new_candidates = []

        if not seed_only:
            ai_candidates = discover_via_ai(existing_ids, existing_names)
            new_candidates.extend(ai_candidates)
            print(f"  ğŸ¤– AI: {len(ai_candidates)} Ğ½Ğ¾Ğ²Ñ‹Ñ… ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²")

        if not ai_only:
            seed_candidates = discover_from_seed_list(existing_ids)
            new_candidates.extend(seed_candidates)
            print(f"  ğŸ“‹ Seed: {len(seed_candidates)} Ğ½Ğ¾Ğ²Ñ‹Ñ… ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ²")

        # Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ñ staging
        staging_ids = {c.get("id") for c in candidates}
        added = 0
        for nc in new_candidates:
            if nc["id"] not in staging_ids:
                candidates.append(nc)
                staging_ids.add(nc["id"])
                added += 1

        save_staging(candidates)
        print(f"\nğŸ“ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {added} Ğ½Ğ¾Ğ²Ñ‹Ñ… ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² (Ğ±Ñ‹Ğ»Ğ¾ {initial_count}, ÑÑ‚Ğ°Ğ»Ğ¾ {len(candidates)})")
        print("\nĞ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³: python tools/company_discovery.py validate")

    elif command == "validate":
        candidates = load_staging()
        if not candidates:
            print("ğŸ“‹ Staging Ğ¿ÑƒÑÑ‚")
            return

        changes = validate_candidates(candidates)
        save_staging(candidates)

        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
        supported = sum(1 for c in candidates if c.get("supported"))
        unsupported = sum(1 for c in candidates if c.get("status") == "unsupported_ats")
        no_ats = sum(1 for c in candidates if c.get("status") == "no_ats_detected")
        print(f"\nğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾: {supported} Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¼ ATS, {unsupported} unsupported, {no_ats} Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½")
        print("\nĞ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³: python tools/company_discovery.py preview")

    elif command == "preview":
        candidates = load_staging()
        if not candidates:
            print("ğŸ“‹ Staging Ğ¿ÑƒÑÑ‚")
            return

        changes = preview_relevant_roles(candidates)
        save_staging(candidates)

        ready = sum(1 for c in candidates if c.get("status") == "ready_to_approve")
        no_roles = sum(1 for c in candidates if c.get("status") == "no_relevant_roles")
        print(f"\nğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾: {ready} ready to approve, {no_roles} Ğ±ĞµĞ· Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ€Ğ¾Ğ»ĞµĞ¹")

    elif command == "list":
        list_candidates()

    else:
        print(f"âŒ ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: {command}")
        print("Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ: search, validate, preview, list")


if __name__ == "__main__":
    main()
