"""
ATS Detector - Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð¸ Ñ€ÐµÐ¼Ð¾Ð½Ñ‚ ATS URL ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:
1. detect_ats(careers_url) - Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ATS Ð¿Ð¾ careers ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ
2. try_repair_company(company_data) - Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð°Ñ‚ÑŒÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ð¹ URL Ð´Ð»Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹
3. repair_all_broken() - Ð¿Ð¾Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ Ð²ÑÐµ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼Ð¸ Ð² companies.json
"""
import re
import json
import requests
from pathlib import Path
from urllib.parse import urlparse

ATS_PATTERNS = {
    "greenhouse": [
        r"boards\.greenhouse\.io/([a-zA-Z0-9_-]+)",
        r"boards-api\.greenhouse\.io/v1/boards/([a-zA-Z0-9_-]+)",
        r"greenhouse\.io.*?/([a-zA-Z0-9_-]+)/jobs",
    ],
    "lever": [
        r"jobs\.lever\.co/([a-zA-Z0-9_-]+)",
        r"api\.lever\.co/v0/postings/([a-zA-Z0-9_-]+)",
    ],
    "smartrecruiters": [
        r"jobs\.smartrecruiters\.com/([a-zA-Z0-9_-]+)",
        r"careers\.smartrecruiters\.com/([a-zA-Z0-9_-]+)",
    ],
    "ashby": [
        r"jobs\.ashbyhq\.com/([a-zA-Z0-9_-]+)",
        r"api\.ashbyhq\.com/posting-api/job-board/([a-zA-Z0-9_-]+)",
    ],
    "workday": [
        r"([a-zA-Z0-9_-]+)\.wd\d+\.myworkdayjobs\.com",
    ],
}

# Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ðµ careers URL Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹
CAREERS_URL_PATTERNS = [
    "{domain}/careers",
    "{domain}/jobs",
    "{domain}/about/careers",
    "{domain}/company/careers",
    "careers.{domain}",
    "jobs.{domain}",
]


def detect_ats(careers_url: str) -> dict | None:
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ careers ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ Ð¸ Ð¸Ñ‰ÐµÑ‚ ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ð° ATS.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ {"ats": "greenhouse", "board_id": "openai", "board_url": "..."} Ð¸Ð»Ð¸ None
    """
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Connection": "keep-alive",
        }
        resp = requests.get(careers_url, headers=headers, timeout=15, allow_redirects=True)
        resp.raise_for_status()
        html = resp.text
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¸ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ URL Ð¿Ð¾ÑÐ»Ðµ Ñ€ÐµÐ´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ð²
        final_url = resp.url
        texts_to_check = [html, final_url]
        
        for ats_name, patterns in ATS_PATTERNS.items():
            for pattern in patterns:
                for text in texts_to_check:
                    match = re.search(pattern, text, re.IGNORECASE)
                    if match:
                        board_id = match.group(1).lower()
                        board_url = build_board_url(ats_name, board_id)
                        api_url = build_api_url(ats_name, board_id)
                        
                        # Verify using API URL
                        if verify_ats_url(api_url):
                            return {
                                "ats": ats_name,
                                "board_id": board_id,
                                "board_url": board_url,
                                "source": careers_url,
                                "verified": True
                            }
        
        return None
        
    except Exception as e:
        return {"error": str(e)}


def build_board_url(ats: str, board_id: str) -> str:
    """Builds the board URL for storing in companies.json (used by parsers)"""
    urls = {
        "greenhouse": f"https://boards.greenhouse.io/{board_id}",
        "lever": f"https://jobs.lever.co/{board_id}",
        "smartrecruiters": f"https://jobs.smartrecruiters.com/{board_id}",
        "ashby": f"https://jobs.ashbyhq.com/{board_id}",
        "workday": "",
    }
    return urls.get(ats, "")


def build_api_url(ats: str, board_id: str) -> str:
    """Builds the API URL for verification"""
    urls = {
        "greenhouse": f"https://boards-api.greenhouse.io/v1/boards/{board_id}/jobs",
        "lever": f"https://api.lever.co/v0/postings/{board_id}?mode=json",
        "smartrecruiters": f"https://api.smartrecruiters.com/v1/companies/{board_id}/postings",
        "ashby": f"https://api.ashbyhq.com/posting-api/job-board/{board_id}",
        "workday": "",
    }
    return urls.get(ats, "")


def verify_ats_url(board_url: str) -> bool:
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ñ‡Ñ‚Ð¾ ATS URL Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""
    if not board_url:
        return False
    try:
        headers = {"User-Agent": "Mozilla/5.0 (compatible; JobTracker/1.0)"}
        resp = requests.get(board_url, headers=headers, timeout=10)
        return resp.status_code == 200
    except:
        return False


def guess_careers_urls(company_name: str, website: str = None) -> list:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ careers URL Ð´Ð»Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸"""
    urls = []
    
    # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ website
    if website:
        domain = website.replace("https://", "").replace("http://", "").rstrip("/")
        for pattern in CAREERS_URL_PATTERNS:
            url = "https://" + pattern.format(domain=domain)
            urls.append(url)
    
    # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ ÑƒÐ³Ð°Ð´Ð°Ñ‚ÑŒ Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸
    slug = company_name.lower().replace(" ", "").replace("-", "").replace(".", "")
    common_domains = [
        f"https://{slug}.com/careers",
        f"https://www.{slug}.com/careers",
        f"https://{slug}.io/careers",
    ]
    urls.extend(common_domains)
    
    return urls


def try_repair_company(company: dict) -> dict | None:
    """
    ÐŸÑ‹Ñ‚Ð°ÐµÑ‚ÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ð¹ ATS URL Ð´Ð»Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸.
    
    Args:
        company: dict Ñ Ð¿Ð¾Ð»ÑÐ¼Ð¸ name, ats, board_url, Ð¸ Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ website, careers_url
    
    Returns:
        dict Ñ Ð½Ð¾Ð²Ñ‹Ð¼Ð¸ ats, board_url ÐµÑÐ»Ð¸ Ð½Ð°ÑˆÐ»Ð¸, Ð¸Ð»Ð¸ None
    """
    company_name = company.get("name", "")
    print(f"ðŸ”§ Trying to repair: {company_name}")
    
    # 1. Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ careers_url - Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ ÐµÐ³Ð¾
    if company.get("careers_url"):
        result = detect_ats(company["careers_url"])
        if result and result.get("verified"):
            print(f"  âœ… Found via careers_url: {result['ats']}")
            return result
    
    # 2. ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ ÑƒÐ³Ð°Ð´Ð°Ñ‚ÑŒ careers URL
    guess_urls = guess_careers_urls(company_name, company.get("website"))
    
    for url in guess_urls:
        result = detect_ats(url)
        if result and result.get("verified"):
            print(f"  âœ… Found via {url}: {result['ats']}")
            return result
    
    # 3. ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ðµ ATS Ñ slug ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸
    slug = company_name.lower().replace(" ", "").replace("-", "").replace(".", "")
    
    direct_urls = [
        ("greenhouse", slug),
        ("lever", slug),
        ("ashby", slug),
    ]
    
    for ats, board_id in direct_urls:
        api_url = build_api_url(ats, board_id)
        if verify_ats_url(api_url):
            print(f"  âœ… Found via direct probe: {ats}")
            return {
                "ats": ats,
                "board_id": board_id,
                "board_url": build_board_url(ats, board_id),
                "verified": True
            }
    
    print(f"  âŒ Could not find working ATS URL")
    return None


def repair_company_in_json(company_id: str, companies_path: str = "data/companies.json") -> bool:
    """
    ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸ÑŽ Ð¿Ð¾ ID, Ð¿Ñ‹Ñ‚Ð°ÐµÑ‚ÑÑ Ð¿Ð¾Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ, Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ JSON Ñ„Ð°Ð¹Ð».
    """
    path = Path(companies_path)
    
    with open(path, "r") as f:
        companies = json.load(f)
    
    # ÐÐ°Ð¹Ñ‚Ð¸ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸ÑŽ
    company = None
    company_idx = None
    for i, c in enumerate(companies):
        if c.get("id") == company_id:
            company = c
            company_idx = i
            break
    
    if not company:
        print(f"Company {company_id} not found")
        return False
    
    # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ
    result = try_repair_company(company)
    
    if result and result.get("verified"):
        # ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        companies[company_idx]["ats"] = result["ats"]
        companies[company_idx]["board_url"] = result["board_url"]
        if result.get("source"):
            companies[company_idx]["careers_url"] = result["source"]
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ
        with open(path, "w") as f:
            json.dump(companies, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Updated {company_id} in {companies_path}")
        return True
    
    return False


def repair_all_broken(companies_path: str = "data/companies.json", 
                      status_from_api: list = None) -> dict:
    """
    ÐŸÑ€Ð¾Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾ Ð²ÑÐµÐ¼ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸ÑÐ¼ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼Ð¸ Ð¸ Ð¿Ñ‹Ñ‚Ð°ÐµÑ‚ÑÑ Ð¸Ñ… Ð¿Ð¾Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ.
    
    Args:
        companies_path: Ð¿ÑƒÑ‚ÑŒ Ðº companies.json
        status_from_api: ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ ÑÐ¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°Ð¼Ð¸ Ð¾Ñ‚ /companies endpoint
    
    Returns:
        {"repaired": [...], "failed": [...]}
    """
    path = Path(companies_path)
    
    with open(path, "r") as f:
        companies = json.load(f)
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ÐºÐ°ÐºÐ¸Ðµ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ ÑÐ»Ð¾Ð¼Ð°Ð½Ñ‹
    broken_ids = set()
    if status_from_api:
        for c in status_from_api:
            if c.get("last_ok") == False:
                broken_ids.add(c.get("id"))
    
    repaired = []
    failed = []
    updated = False
    
    for i, company in enumerate(companies):
        company_id = company.get("id")
        
        # ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ ÐµÑÐ»Ð¸ Ð½Ðµ Ð² ÑÐ¿Ð¸ÑÐºÐµ ÑÐ»Ð¾Ð¼Ð°Ð½Ð½Ñ‹Ñ… (ÐµÑÐ»Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½)
        if status_from_api and company_id not in broken_ids:
            continue
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ URL
        current_url = company.get("board_url", "")
        if current_url and verify_ats_url(current_url):
            continue  # URL Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
        
        # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ
        result = try_repair_company(company)
        
        if result and result.get("verified"):
            companies[i]["ats"] = result["ats"]
            companies[i]["board_url"] = result["board_url"]
            if result.get("source"):
                companies[i]["careers_url"] = result["source"]
            
            repaired.append({
                "id": company_id,
                "name": company.get("name"),
                "new_ats": result["ats"],
                "new_url": result["board_url"]
            })
            updated = True
        else:
            failed.append({
                "id": company_id,
                "name": company.get("name")
            })
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÐµÑÐ»Ð¸ Ð±Ñ‹Ð»Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
    if updated:
        with open(path, "w") as f:
            json.dump(companies, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… Saved updates to {companies_path}")
    
    return {"repaired": repaired, "failed": failed}


# CLI interface
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "repair":
            # Repair all broken companies
            result = repair_all_broken()
            print(f"\nRepaired: {len(result['repaired'])}")
            print(f"Failed: {len(result['failed'])}")
            
        elif sys.argv[1] == "test":
            # Test detection on a few URLs
            test_urls = [
                "https://openai.com/careers",
                "https://notion.so/careers", 
                "https://stripe.com/jobs",
                "https://linear.app/careers",
            ]
            
            for url in test_urls:
                print(f"\n{url}")
                result = detect_ats(url)
                if result and not result.get("error"):
                    print(f"  âœ… {result['ats']} â†’ {result['board_url'][:60]}...")
                else:
                    print(f"  âŒ {result}")
                    
        elif sys.argv[1] == "check":
            # Check a specific company by name
            if len(sys.argv) > 2:
                company_name = " ".join(sys.argv[2:])
                result = try_repair_company({"name": company_name})
                print(f"\nResult: {result}")
    else:
        print("Usage:")
        print("  python ats_detector.py test     - test detection on sample URLs")
        print("  python ats_detector.py repair   - repair all broken companies")
        print("  python ats_detector.py check <company name> - check specific company")
